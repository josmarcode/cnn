{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Redes Convolucionales**\n",
    "### Por **Josmar Dominguez** (16-10315)\n",
    "\n",
    "## Entrenamiento de red neuronal convolucional\n",
    "Este notebook se encarga de importar los datos de entrenamiento y testeo, entrenar la red neuronal convolucional y guardar los parametros de la red entrenada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importar librerías**\n",
    "Se importan las librerías a emplear,\n",
    "* ```torch``` para el manejo de la red neuronal\n",
    "* ```torchvision``` para la importación de los datos\n",
    "* ```matplotlib``` para la visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and model\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importar datos**\n",
    "Se importan los datos de entrenamiento y testeo y se crean los *dataloaders* para el entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the .pt file\n",
    "file_path = \"data/train_data_aug.pt\"\n",
    "\n",
    "# Load the train data\n",
    "try:\n",
    "    train_data = torch.load(file_path)\n",
    "except:\n",
    "    print(\"File not found. Please, run the _data_ notebook first.\")\n",
    "\n",
    "# Load the test data\n",
    "test_data = datasets.CIFAR100(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Create a dictionary to map the labels to the class names\n",
    "dict_labels = test_data.class_to_idx\n",
    "dict_ids = {v: k for k, v in dict_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the number of images in the training dataset\n",
    "print(f\"Number of training images: {len(train_data)}\")\n",
    "\n",
    "# Show the first 5 images with their transformed versions\n",
    "fig, ax = plt.subplots(5, 2, figsize=(2, 6))\n",
    "for i in range(5):\n",
    "    ax[i][0].imshow(train_data[i][0].permute(1, 2, 0))\n",
    "    ax[i][0].set_title(dict_ids[train_data[i][1]])\n",
    "    ax[i][0].axis(\"off\")\n",
    "    ax[i][1].imshow(train_data[i + len(train_data) // 2][0].permute(1, 2, 0))\n",
    "    ax[i][1].set_title(dict_ids[train_data[i + len(train_data) // 2][1]])\n",
    "    ax[i][1].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Verify the size of the data loaders\n",
    "print(f\"Number of batches in the train loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in the test loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Entrenamiento del modelo**\n",
    "Función para entrenar un modelo dado con el dataset de entrenamiento de CIFAR100, para un número de épocas dado, con un optimizador dado y un learning rate dado.\n",
    "Además, se emplea un *scheduler* para el learning rate, el cual disminuye el learning rate cada $n$ épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model:nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    epochs: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    "    scheduler: torch.optim.lr_scheduler) -> tuple:\n",
    "    \"\"\"\n",
    "    Train a model using the specified optimizer, criterion, and scheduler.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The model to be trained.\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        The train data loader.\n",
    "    test_loader : torch.utils.data.DataLoader\n",
    "        The test data loader.\n",
    "    epochs : int\n",
    "        The number of epochs.\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimizer.\n",
    "    criterion : nn.Module\n",
    "        The criterion.\n",
    "    device : torch.device\n",
    "        The device to be used.\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        The scheduler.\n",
    "    \"\"\"\n",
    "    \n",
    "    model_stats = {\n",
    "        'train_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_loss': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                # Set the model to training mode\n",
    "                model.train()\n",
    "                \n",
    "                # Set the loader to the train loader\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                # Set the model to evaluation mode\n",
    "                model.eval()\n",
    "                \n",
    "                # Set the loader to the test loader\n",
    "                data_loader = test_loader\n",
    "            \n",
    "            running_loss = 0\n",
    "            running_accuracy = 0\n",
    "            total_images = 0\n",
    "                        \n",
    "            # Iterate over the data loader\n",
    "            for step, (images, labels) in enumerate(data_loader):\n",
    "                # Move the images and labels to the specified device\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Forward pass\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(images)\n",
    "\n",
    "                    _, preds = torch.max(output, 1)\n",
    "                    \n",
    "                    loss = criterion(output, labels)\n",
    "\n",
    "                    # Make backward and optimization\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Update the running loss\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                model_stats[f'{phase}_loss'].append(loss.item() * images.size(0))\n",
    "                \n",
    "                # Update the running accuracy\n",
    "                running_accuracy += (output.argmax(1) == labels).sum().item()\n",
    "                model_stats[f'{phase}_accuracy'].append((output.argmax(1) == labels).sum().item())\n",
    "                \n",
    "                # Update the total number of images\n",
    "                total_images += labels.size(0)\n",
    "                \n",
    "            # Print the loss and accuracy\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                print(f'\\tTrain loss: {running_loss / len(data_loader):.4f}')\n",
    "                print(f'\\tTrain accuracy: {running_accuracy / total_images:.4f}\\n')\n",
    "            else:\n",
    "                print(f'Test loss: {running_loss / len(data_loader):.4f}')\n",
    "                print(f'Test accuracy: {running_accuracy / total_images:.4f}')\n",
    "                print('-' * 50)\n",
    "    \n",
    "    return model_stats, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cargar el modelo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **VGG16**\n",
    "Se cargará el modelo preentrenado ```VGG16``` y se entrenará con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Import the model\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "num_features = vgg16.classifier[-1].in_features\n",
    "\n",
    "vgg16.classifier[-1] = nn.Linear(num_features, 100)\n",
    "\n",
    "# Move the model to the specified device\n",
    "vgg16.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Define the criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "train_results = train_model(\n",
    "    vgg16,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=30,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "vgg16_stats = train_results[0]\n",
    "vgg16 = train_results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Análisis superficial de los resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = vgg16_stats['train_loss']\n",
    "train_accuracy = vgg16_stats['train_accuracy']\n",
    "test_loss = vgg16_stats['test_loss']\n",
    "test_accuracy = vgg16_stats['test_accuracy']\n",
    "\n",
    "# Plot the loss and accuracy\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(train_loss, label='train')\n",
    "ax[0].plot(test_loss, label='test')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(train_accuracy, label='train')\n",
    "ax[1].plot(test_accuracy, label='test')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(vgg16.state_dict(), 'models/vgg16.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
